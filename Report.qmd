---
lang: pt  
title: "GED-16: Análise de Regressão"
subtitle: "AULA01: Prática (2o. semestre/2023)"
author: "Alexandre & Deodato & Pedro Igor"
date: "2023-08-01"  
format:
  html:
    theme: cosmo
execute:
  echo: true
  eval: true
  warning: false    
---

```{r include = FALSE}
library(tidyverse)
library(gridExtra)
library(lmtest)
```

------------------------------------------------------------------------

### Introdução

Os dados disponíveis no arquivo `data/owid.csv` foram obtidos do portal [Our World in Data](https://ourworldindata.org/), cuja missão é publicar pesquisas e dados relacionados a grandes problemas mundiais como pobreza, doenças, fome, mudanças climáticas, guerras, riscos existenciais e desigualdade.

Os dados originais foram pré-processados no sentido de remover observações faltantes. Há um total de 985 observações coletadas para 21 variáveis:

1.  `continent`: continente em que está o país
2.  `entity`: nome do país
3.  `code`: código do país
4.  `year`: ano
5.  `birth_rate`: número de nascimentos com vida por 1.000 habitantes na população.
6.  `child_mortality`: mortes de crianças menores de 5 anos de idade (% nascimentos)
7.  `co2_emission_pc`: emissões anuais de CO2 per capita (t/pessoa)
8.  `deaths_solid_fuels_pollution`: mortes resultantes de poluição por queima de combustíveis sólidos em ambientes internos (/100K)
9.  `deaths_particulate_pollution`: mortes resultantes de poluição por material particulado em ambientes externos (/100K)
10. `deaths_air_pollution`: mortes resultantes de poluição do ar ambiente (/100K)
11. `deaths_ozone`: mortes resultantes de poluição por ozônio em ambientes externos (%)
12. `deaths_sanitation`: mortes resultantes de falta ou precariedade de acesso a saneamento básico (100K)
13. `electricity_demand`: geração total de eletricidade anual, ajustada por importação e exportação de eletricidade (TWh)
14. `energy_use_pc`: consumo de energia médio anual (eletricidade, transporte, aquecimento, preparo de alimentos) per capita (KWh/pessoa)
15. `expected_schooling`: expectativa do número de anos de educação que uma criança que entra no sistema escolar deve receber
16. `happiness_cantril_ladder`: nível de felicidade médio populacional (0-10)
17. `gdp_pc`: produto interno bruto per capita (\$ internacional, referência 2017)
18. `life_expectancy`: expectativa de vida no nascimento (anos)
19. `milk_consumption_pc`: consumo de leite médio anual per capita (kg)
20. `no_water`: população sem acesso a fontes seguras de água (encanada, poços, fontes, chuva e envasada) (%)
21. `urban_population_percent`: população habitante de áreas urbanas (% população total)

------------------------------------------------------------------------

### Análise Exploratória de Dados

Conduza a análise exploratória da massa de dados `owid`, a fim de compreender suas características principais.\
Voltaremos a utilizar essa massa de dados em atividades futuras.

```{r}
rm(list = ls())
owid <- read_delim("data/owid.csv", delim = ",", col_names = TRUE)
owid$continent <- as.factor(owid$continent)
summary(owid)
```

Note que para várias colunas há um intervalo muito grande entre o terceiro quartil e o valor máximo, o que pode indicar _outliers_ nos dados disponíveis. Semelhantemente para algumas colunas com `deaths_particulate_pollution`, `deaths_air_pollution` e `energy_use_pc` há um grande intervalo entre o valor mínimo e o primeiro quartil, indicando a exsitência de mais _outliers_.

#### Resumos gráficos de `life_expectancy`, possível variável de respota.

```{r}
ggplot(owid, aes(x = life_expectancy)) +
    geom_histogram(aes(y = after_stat(density))) +
    geom_density(lwd = 1, colour = 4,
                 fill = 4, alpha = 0.25) +
    geom_rug(alpha = 0.5) +
    labs(x = "Life Expectancy (years)", y = "Density")
```

O gráfico de densidade de _kernel_ ajuda a visualizar melhor os picos de espectativa de vida entre 70 e 80 anos, maior de todos e outros menores por volta dos 55, 65 e 85.

```{r}
ggplot(owid, aes(x = life_expectancy, y = "")) +
    geom_errorbar(stat = "boxplot", width = 0.1) +
    geom_boxplot () +
    geom_rug(alpha = 0.5) +
    labs(y = "", x = "Life Expectancy (years)")
```

#### Resumos gráficos multidimensionais

```{r}
ggplot(owid, aes(x = life_expectancy, y = continent)) +
  geom_errorbar(stat = "boxplot", width = 0.1) +
  geom_boxplot() +
  labs(x = "Life Expectancy (years)", y = "Continent")
```

```{r}
ggplot(owid, aes(y = life_expectancy, x = co2_emission_pc)) +
  geom_point(aes(color = continent)) +
  labs(y = "Life Expectancy (years)", x = "CO2 Emissions (tons/person)")
```

```{r}
ggplot(owid, aes(y = life_expectancy, x = electricity_demand)) +
geom_point() +
labs(x = "Eletricity Demand (TWh)", y = "Life Expectancy (years)")
```

```{r}
ggplot(owid, aes(y = life_expectancy, x = 1/electricity_demand)) +
geom_point() +
labs(x = "1/Ele(tricity Demand (1/TWh)", y = "Life Expectancy (years)")
```

```{r}
ggplot(owid, aes(y = life_expectancy, x = sqrt(electricity_demand))) +
geom_point() +
labs(x = "sqrt(Eletricity Demand)", y = "Life Expectancy (years)")
```


```{r}
ggplot(owid, aes(y = life_expectancy, x = log2(electricity_demand))) +
geom_point() +
labs(x = "Log2(Eletricity Demand)", y = "Life Expectancy (years)")
```

------------------------------------------------------------------------

### Análise de Regressão


1. Assuma que um modelo de regressão linear simples é adequado para modelar a relação da variável de resposta `happiness_cantril_ladder` a cada uma das variáveis explicativas: `birth_rate`, `deaths_air_pollution`,`expected_schooling`, `life_expectancy`.

+ Construa um modelo de regressão para cada um desses pares de variáveis;

```{r}
br_rls <- lm(happiness_cantril_ladder ~ birth_rate, data = owid)
dap_rls <- lm(happiness_cantril_ladder ~ deaths_air_pollution, data = owid)
es_rls <- lm(happiness_cantril_ladder ~ expected_schooling, data = owid)
le_rls <- lm(happiness_cantril_ladder ~ life_expectancy, data = owid)
```

+ Construa gráficos de dispersão (separados) com as retas de regressão ajustadas para cada caso;

```{r}
ggplot(owid, aes(x = birth_rate, y = happiness_cantril_ladder)) +
  geom_point() +
  # adiciona reta de regressão estimada
  geom_smooth(method = lm, se = FALSE) + 
  labs(x = "Birth Rate (#/1K)", y = "Happiness Cantril Ladder")
```

```{r}
ggplot(owid, aes(x = deaths_air_pollution, y = happiness_cantril_ladder)) +
  geom_point() +
  # adiciona reta de regressão estimada
  geom_smooth(method = lm, se = FALSE) + 
  labs(x = "Deaths Air Pollution (#/100K)", y = "Happiness Cantril Ladder")
```

```{r}
ggplot(owid, aes(x = expected_schooling, y = happiness_cantril_ladder)) +
  geom_point() +
  # adiciona reta de regressão estimada
  geom_smooth(method = lm, se = FALSE) + 
  labs(x = "Expected Schoolling (years)", y = "Happiness Cantril Ladder")
```

```{r}
ggplot(owid, aes(x = life_expectancy, y = happiness_cantril_ladder)) +
  geom_point() +
  # adiciona reta de regressão estimada
  geom_smooth(method = lm, se = FALSE) + 
  labs(x = "Life Expectancy (years)", y = "Happiness Cantril Ladder")
```

+ Obtenha o MSE para cada modelo. Que variável explicativa produz menor variabilidade em torno da reta de regressão ajustada?

```{r}
summary(br_rls)$sigma^2
summary(dap_rls)$sigma^2
summary(es_rls)$sigma^2
summary(le_rls)$sigma^2
```

A variável explicativa `death_air_pollution` possuiu o menor valor de MSE, ou seja, produz menor variabilidade em torno da reta de regressão ajustada.

+ Utilizando R2 como critério, qual das variáveis explicativas contribui para a maior redução na variabilidade da resposta `happiness_cantril_ladder`?

```{r}
summary(br_rls)$r.squared
summary(dap_rls)$r.squared
summary(es_rls)$r.squared
summary(le_rls)$r.squared
```
A variável `death_air_pollution` também possuiu o maior valor para a estatística R2, assim ela contruibui para a maior redução da variabilidade da resposta.

2. Para cada nível da variável categórica `continent`, construa um modelo de regressão para a variável de resposta `happiness_cantril_ladder` em função da variável escolhida no último item da questão anterior.  Assuma que o modelo de 1a. ordem é adequado para modelar essas relações.

+ Obtenha os modelos de regressão ajustados. As funções de regressão estimadas são semelhantes para todos os níveis da variável `continent`? Discuta.

```{r}
# África
africa <- owid[owid$continent == "Africa",]
africa_rls <- lm(happiness_cantril_ladder ~ deaths_air_pollution, data = africa)

# Ásia
asia <- owid[owid$continent == "Asia",]
asia_rls <- lm(happiness_cantril_ladder ~ deaths_air_pollution, data = asia)

# Europa
europe <- owid[owid$continent == "Europe",]
europe_rls <- lm(happiness_cantril_ladder ~ deaths_air_pollution, data = europe)

# North America
north_america <- owid[owid$continent == "North America",]
north_america_rls <- lm(happiness_cantril_ladder ~ deaths_air_pollution, data = north_america)

# Oceania
oceania <- owid[owid$continent == "Oceania",]
oceania_rls <- lm(happiness_cantril_ladder ~ deaths_air_pollution, data = oceania)

# South America
south_america <- owid[owid$continent == "South America",]
south_america_rls <- lm(happiness_cantril_ladder ~ deaths_air_pollution, data = south_america)

```

```{r}
# Funcoes de regressao estimadas
africa_rls$coefficients
asia_rls$coefficients
europe_rls$coefficients
north_america_rls$coefficients
oceania_rls$coefficients
south_america_rls$coefficients
```

Com isso, nota-se que as funções de regressão estimadas são semelhantes para todos os níveis da variável `continent`, exceto para o continente `Oceania`, já que o valor do coeficiente angular é negativo para os demais continentes e positivo para o continente `Oceania`. Dentre os outros continentes nota-se que eles tem um coeficiente angular muito próximo, o que indica que a função de regressão estimada é semelhante para esses níveis da variável `continent`.

+ Obtenha o MSE para cada nível da variável `continent` A variabilidade em torno da reta de regressão ajustada é semelhante para todos os níveis?

```{r}
# África
summary(africa_rls)$sigma^2
# Ásia
summary(asia_rls)$sigma^2
# Europa
summary(europe_rls)$sigma^2
# North America
summary(north_america_rls)$sigma^2
# Oceania
summary(oceania_rls)$sigma^2
# South America
summary(south_america_rls)$sigma^2
```

Novamente temos uma diferença em relação ao continente `Oceania`, já que o valor do MSE é muito menor que os demais continentes. Dentre os outros continentes nota-se que eles tem um valor de MSE muito próximo, o que indica que a variabilidade em torno da reta de regressão ajustada é semelhante para esses níveis da variável `continent`, estando em uma mesma ordem de grandeza. Já o do continente `Oceania` é muito menor que os demais.

+ Construa intervalos de confiança 95% para o coeficiente angular da reta de regressão para os continentes `North America` e `South America`. As retas de regressão para os diferentes níveis parecem ter mesma inclinação? O que se pode concluir?

```{r}
# North America
confint(north_america_rls, level = 0.95)
# South America
confint(south_america_rls, level = 0.95)
```

Com uma confiança de 95%, nota-se que os intervalos de confiança não se interceptam, o que indica que as retas de regressão para os diferentes níveis não tem a mesma inclinação.

+ Construa intervalos de confiança para a resposta esperada correspondendo a `deaths_air_pollution` = 50, para os continentes `North America` e `South America` O que se pode concluir?

```{r}
# North America
predict(north_america_rls, newdata = data.frame(deaths_air_pollution = 50), interval = "confidence", level = 0.95)
# South America
predict(south_america_rls, newdata = data.frame(deaths_air_pollution = 50), interval = "confidence", level = 0.95)
```

Com uma confiança de 95%, nota-se que os intervalos de confiança não se interceptam, o que indica que as respostas esperadas para os continentes `North America` e `South America` não são iguais. Além disso, nota-se que o intervalo de confiança de ambos é pequeno, monstrando que a resposta esperada para `deaths_air_pollution` = 50 é bem próxima do valor estimado.

+ Construa intervalos de previsão para uma nova observação de cada continente (`North America` e `South America`) que tenha `deaths_air_pollution` = 50. O que se pode concluir?

```{r}
# Novo valor de deaths_air_pollution
new_x <- data.frame(deaths_air_pollution = 50)
# North America
predict(north_america_rls, newdata = new_x, interval = "prediction", level = 0.95)
# South America
predict(south_america_rls, newdata = new_x, interval = "prediction", level = 0.95)
```

Para uma nova observação de cada continente (`North America` e `South America`) que tenha `deaths_air_pollution` = 50, nota-se que os intervalos de previsão são muito mais dispersos que o anterior, mostrando que a previsão para uma nova observação é muito mais incerta que a resposta esperada para `deaths_air_pollution` = 50.

3. Construa um modelo de regressão para a variável de resposta `happiness_cantril_ladder` em função de `gdp_pc`. Assuma que o modelo de 1a. ordem é adequado para modelar essas relações. Faz sentido aplicar alguma transformação à variável explicativa? Replique os procedimentos realizados no  item (1) para um modelo considerando a variável explicativa em sua forma original ou transformada.

```{r}
# Analise de regressao para a variavel de resposta happiness_cantril_ladder em funcao de gdp_pc
gdp_rls <- lm(happiness_cantril_ladder ~ gdp_pc, data = owid)

ggplot(owid, aes(x = gdp_pc, y = happiness_cantril_ladder)) +
  geom_point() +
  # adiciona reta de regressão estimada
  geom_smooth(method = lm, se = FALSE) + 
  labs(x = "gdp_pc", y = "Happiness Cantril Ladder")
```

Com essa analise podemos perceber uma não linearidade em relação às variáveis `happiness_cantril_ladder` e `gdp_pc`, o que indica que o modelo de 1a. ordem não é adequado para modelar essas relações. Assim, faz sentido aplicar alguma transformação à variável explicativa.

```{r}
gdp_rls_inv = lm(happiness_cantril_ladder ~ 1/gdp_pc, data = owid)
ggplot(owid, aes(x = 1/gdp_pc, y = happiness_cantril_ladder)) +
  geom_point() +
  # adiciona reta de regressão estimada
  geom_smooth(method = lm, se = FALSE) + 
  labs(x = "1/gdp_pc", y = "Happiness Cantril Ladder")
gdp_rls_log = lm(happiness_cantril_ladder ~ log10(gdp_pc), data = owid)
ggplot(owid, aes(x = log10(gdp_pc) , y = happiness_cantril_ladder)) +
  geom_point() +
  # adiciona reta de regressão estimada
  geom_smooth(method = lm, se = FALSE) + 
  labs(x = "log(gdp_pc)", y = "Happiness Cantril Ladder")

```
Podemos observar que o modelo logaritmo parece ser uma relação mais adequada para modelar essas relações. Para mostrar isso vamos comprar o MSE e o R2 para cada uma das transformações.

```{r}
summary(gdp_rls)$sigma^2
summary(gdp_rls_inv)$sigma^2
summary(gdp_rls_log)$sigma^2

summary(gdp_rls)$r.squared
summary(gdp_rls_inv)$r.squared
summary(gdp_rls_log)$r.squared
```

Com esses parametros podemos perceber que o modelo logaritmo é o que apresenta o menor MSE e o maior R2, o que indica que ele é o mais adequado para modelar essas relações.

### Diagnóstico

1. Para cada um dos modelos de regressão ajustados no item (1) da seção anterior, realize o diagnóstico através da análise dos resíduos e apresente um resumo de suas conclusões. O modelo de regressão linear simples clássico de 1a. ordem é adequado a alguma das situações investigadas?

Inicialmente, vamos analisar o resumo do modelo de regressão ajustado

```{r}
summary(br_rls)
summary(dap_rls)
summary(es_rls)
summary(le_rls)
```

Agora vamos analisar os modelos por Linearidade, Homocedasticidade, Outliers, Independência e Normalidade.

##### Linearidade

+ Birth Rate

```{r}
br_rls_data <- owid %>%
  mutate(fitted = br_rls$fit) %>%
  mutate(resid = br_rls$res)

# Gera gráficos dos resíduos: 
ggplot(br_rls_data, aes(x = fitted, y = resid)) +
  geom_point() +
  geom_hline(yintercept = 0, linetype = "dashed") +
  ggtitle("dados originais: modelo hcl ~ br") + 
  labs(y = "resíduos", x = "resposta ajustada (hcl)") 
ggplot(br_rls_data, aes(x = birth_rate, y = resid)) +
  geom_point() +
  geom_hline(yintercept = 0, linetype = "dashed") +
  ggtitle("dados originais: modelo hcl ~ br") + 
  labs(y = "resíduos", x = "variável explicativa (br)")
```

+ Deaths Air Pollution

```{r}
dap_rls_data <- owid %>%
  mutate(fitted = dap_rls$fit) %>%
  mutate(resid = dap_rls$res)

# Gera gráficos dos resíduos:
ggplot(dap_rls_data, aes(x = fitted, y = resid)) +
  geom_point() +
  geom_hline(yintercept = 0, linetype = "dashed") +
  ggtitle("dados originais: modelo hcl ~ dap") + 
  labs(y = "resíduos", x = "resposta ajustada (hcl)")
ggplot(dap_rls_data, aes(x = deaths_air_pollution, y = resid)) +
  geom_point() +
  geom_hline(yintercept = 0, linetype = "dashed") +
  ggtitle("dados originais: modelo hcl ~ dap") + 
  labs(y = "resíduos", x = "variável explicativa (dap)")
```

+ Expected Schooling

```{r}
es_rls_data <- owid %>%
  mutate(fitted = es_rls$fit) %>%
  mutate(resid = es_rls$res)

# Gera gráficos dos resíduos:
ggplot(es_rls_data, aes(x = fitted, y = resid)) +
  geom_point() +
  geom_hline(yintercept = 0, linetype = "dashed") +
  ggtitle("dados originais: modelo hcl ~ es") + 
  labs(y = "resíduos", x = "resposta ajustada (hcl)")
ggplot(es_rls_data, aes(x = expected_schooling, y = resid)) +
  geom_point() +
  geom_hline(yintercept = 0, linetype = "dashed") +
  ggtitle("dados originais: modelo hcl ~ es") + 
  labs(y = "resíduos", x = "variável explicativa (es)")
```

+ Life Expectancy

```{r}
le_rls_data <- owid %>%
  mutate(fitted = le_rls$fit) %>%
  mutate(resid = le_rls$res)

# Gera gráficos dos resíduos:
ggplot(le_rls_data, aes(x = fitted, y = resid)) +
  geom_point() +
  geom_hline(yintercept = 0, linetype = "dashed") +
  ggtitle("dados originais: modelo hcl ~ le") + 
  labs(y = "resíduos", x = "resposta ajustada (hcl)")
ggplot(le_rls_data, aes(x = life_expectancy, y = resid)) +
  geom_point() +
  geom_hline(yintercept = 0, linetype = "dashed") +
  ggtitle("dados originais: modelo hcl ~ le") + 
  labs(y = "resíduos", x = "variável explicativa (le)")
```

##### Homocedasticidade

+ Birth Rate

```{r}
ggplot(br_rls_data, aes(x = fitted, y = abs(resid))) +
  geom_point() +
  geom_hline(yintercept = 0, linetype = "dashed") +
  ggtitle("dados originais: modelo hcl ~ br") +
  labs(y = "|resíduos|", x = "resposta ajustada (hcl)")
ggplot(br_rls_data, aes(x = birth_rate, y = abs(resid))) +
  geom_point() +
  geom_hline(yintercept = 0, linetype = "dashed") +
  ggtitle("dados originais: modelo hcl ~ br") +
  labs(y = "|resíduos|", x = "variável explicativa (br)")
```

Para concluir se há homocedasticidade, vamos realizar o teste de Breusch-Pagan.

```{r}
# Teste de Breusch-Pagan
bptest(br_rls, ~ birth_rate, data = owid)
```

O valor do p-valor é menor que 0.05, o que indica que há heterocedasticidade, ou seja, a variância dos resíduos não é constante.

+ Deaths Air Pollution

```{r}
ggplot(dap_rls_data, aes(x = fitted, y = abs(resid))) +
  geom_point() +
  geom_hline(yintercept = 0, linetype = "dashed") +
  ggtitle("dados originais: modelo hcl ~ dap") +
  labs(y = "|resíduos|", x = "resposta ajustada (hcl)")
ggplot(dap_rls_data, aes(x = deaths_air_pollution, y = abs(resid))) +
  geom_point() +
  geom_hline(yintercept = 0, linetype = "dashed") +
  ggtitle("dados originais: modelo hcl ~ dap") +
  labs(y = "|resíduos|", x = "variável explicativa (dap)")
```

Para concluir se há homocedasticidade, vamos realizar o teste de Breusch-Pagan.

```{r}
# Teste de Breusch-Pagan
bptest(dap_rls, ~ deaths_air_pollution, data = owid)
```

O valor do p-valor é maior que 0.05, o que indica que não há heterocedasticidade, ou seja, aceita-se a hipótese nula de que a variância dos resíduos é constante.

+ Expected Schooling

```{r}
ggplot(es_rls_data, aes(x = fitted, y = abs(resid))) +
  geom_point() +
  geom_hline(yintercept = 0, linetype = "dashed") +
  ggtitle("dados originais: modelo hcl ~ es") +
  labs(y = "|resíduos|", x = "resposta ajustada (hcl)")
ggplot(es_rls_data, aes(x = expected_schooling, y = abs(resid))) +
  geom_point() +
  geom_hline(yintercept = 0, linetype = "dashed") +
  ggtitle("dados originais: modelo hcl ~ es") +
  labs(y = "|resíduos|", x = "variável explicativa (es)")
```

Para concluir se há homocedasticidade, vamos realizar o teste de Breusch-Pagan.

```{r}
# Teste de Breusch-Pagan
bptest(es_rls, ~ expected_schooling, data = owid)
```

O valor do p-valor foi bem maior que 0.05, o que indica que não há heterocedasticidade, ou seja, aceita-se a hipótese nula de que a variância dos resíduos é constante.

+ Life Expectancy

```{r}
ggplot(le_rls_data, aes(x = fitted, y = abs(resid))) +
  geom_point() +
  geom_hline(yintercept = 0, linetype = "dashed") +
  ggtitle("dados originais: modelo hcl ~ le") +
  labs(y = "|resíduos|", x = "resposta ajustada (hcl)")
ggplot(le_rls_data, aes(x = life_expectancy, y = abs(resid))) +
  geom_point() +
  geom_hline(yintercept = 0, linetype = "dashed") +
  ggtitle("dados originais: modelo hcl ~ le") +
  labs(y = "|resíduos|", x = "variável explicativa (le)")
```

Para concluir se há homocedasticidade, vamos realizar o teste de Breusch-Pagan.

```{r}
# Teste de Breusch-Pagan
bptest(le_rls, ~ life_expectancy, data = owid)
```

O valor do p-valor foi bem maior que 0.05, o que indica que não há heterocedasticidade, ou seja, aceita-se a hipótese nula de que a variância dos resíduos é constante.

##### Outliers

Para identificar os outliers é importante utilizar os resíduos semi-studentizados, que são os resíduos divididos pelo desvio padrão dos resíduos. Assim, vamos analisar os gráficos dos resíduos semi-studentizados.

+ Birth Rate

```{r}
# criar nova coluna para os residuos semi-studentizados
br_rls_data <- br_rls_data %>%
  mutate(resid_ss = rstandard(br_rls))

# Gera gráficos dos resíduos semi-studentizados:
ggplot(br_rls_data, aes(x = fitted, y = resid_ss)) +
  geom_point() +
  geom_hline(yintercept = c(-4, -3, 0, 3, 4), 
             linetype = "dashed", 
             color = c("red", "orange", "black", "orange", "red") ) +
  ylim(-6, 6) +
  ggtitle("dados transformados: modelo hcl ~ br") +
  labs(y = "resíduos padronizados", x = "resposta ajustada (hcl)")
ggplot(br_rls_data, aes(x = birth_rate, y = resid_ss)) +
  geom_point() +
  geom_hline(yintercept = c(-4, -3, 0, 3, 4), 
             linetype = "dashed", 
             color = c("red", "orange", "black", "orange", "red") ) +
  ylim(-6, 6) +
  ggtitle("dados transformados: modelo hcl ~ br") +
  labs(y = "resíduos padronizados", x = "variável explicativa (br)")
```

Nota-se que temos alguns pontos com módulo do resíduo semi-studentizado próximos a 3, o que pode indicar a existência de outliers mas a evidência é fraca e não se deve realizar a exclusão de nenhum ponto por enquanto.

+ Deaths Air Pollution

```{r}
# criar nova coluna para os residuos semi-studentizados
dap_rls_data <- dap_rls_data %>%
  mutate(resid_ss = rstandard(dap_rls))

# Gera gráficos dos resíduos semi-studentizados:
ggplot(dap_rls_data, aes(x = fitted, y = resid_ss)) +
  geom_point() +
  geom_hline(yintercept = c(-4, -3, 0, 3, 4), 
             linetype = "dashed", 
             color = c("red", "orange", "black", "orange", "red") ) +
  ylim(-6, 6) +
  ggtitle("dados transformados: modelo hcl ~ dap") +
  labs(y = "resíduos padronizados", x = "resposta ajustada (hcl)")
ggplot(dap_rls_data, aes(x = deaths_air_pollution, y = resid_ss)) +
  geom_point() +
  geom_hline(yintercept = c(-4, -3, 0, 3, 4), 
             linetype = "dashed", 
             color = c("red", "orange", "black", "orange", "red") ) +
  ylim(-6, 6) +
  ggtitle("dados transformados: modelo hcl ~ dap") +
  labs(y = "resíduos padronizados", x = "variável explicativa (dap)")
```

Nota-se em ambos os gráficos a existência de pontos de resíduos semi-studentizados maiores que 3, indicando uma forte possibilidade de outliers. Assim, é mais recomendade nesse caso excluir esses pontos.

+ Expected Schooling

```{r}
# criar nova coluna para os residuos semi-studentizados
es_rls_data <- es_rls_data %>%
  mutate(resid_ss = rstandard(es_rls))

# Gera gráficos dos resíduos semi-studentizados:
ggplot(es_rls_data, aes(x = fitted, y = resid_ss)) +
  geom_point() +
  geom_hline(yintercept = c(-4, -3, 0, 3, 4), 
             linetype = "dashed", 
             color = c("red", "orange", "black", "orange", "red") ) +
  ylim(-6, 6) +
  ggtitle("dados transformados: modelo hcl ~ es") +
  labs(y = "resíduos padronizados", x = "resposta ajustada (hcl)")
ggplot(es_rls_data, aes(x = expected_schooling, y = resid_ss)) +
  geom_point() +
  geom_hline(yintercept = c(-4, -3, 0, 3, 4), 
             linetype = "dashed", 
             color = c("red", "orange", "black", "orange", "red") ) +
  ylim(-6, 6) +
  ggtitle("dados transformados: modelo hcl ~ es") +
  labs(y = "resíduos padronizados", x = "variável explicativa (es)")
```

Alguns pontos se aproximam de 3, mas não o suficiente para indicar a existência de outliers.

+ Life Expectancy

```{r}
# criar nova coluna para os residuos semi-studentizados
le_rls_data <- le_rls_data %>%
  mutate(resid_ss = rstandard(le_rls))

# Gera gráficos dos resíduos semi-studentizados:
ggplot(le_rls_data, aes(x = fitted, y = resid_ss)) +
  geom_point() +
  geom_hline(yintercept = c(-4, -3, 0, 3, 4), 
             linetype = "dashed", 
             color = c("red", "orange", "black", "orange", "red") ) +
  ylim(-6, 6) +
  ggtitle("dados transformados: modelo hcl ~ le") +
  labs(y = "resíduos padronizados", x = "resposta ajustada (hcl)")
ggplot(le_rls_data, aes(x = life_expectancy, y = resid_ss)) +
  geom_point() +
  geom_hline(yintercept = c(-4, -3, 0, 3, 4), 
             linetype = "dashed", 
             color = c("red", "orange", "black", "orange", "red") ) +
  ylim(-6, 6) +
  ggtitle("dados transformados: modelo hcl ~ le") +
  labs(y = "resíduos padronizados", x = "variável explicativa (le)")
```

Temos novamente alguns pontos com módulo do resíduo semi-studentizado próximos a 3, o que pode indicar a existência de outliers mas a evidência é fraca e não se deve realizar a exclusão de nenhum ponto por enquanto.

##### Independência

Para a independência iremos utilizar o teste de Durbin-Watson.

+ Birth Rate

```{r}
# Teste de Durbin-Watson
dwtest(br_rls, ~ birth_rate, data = owid)
```

O p-valor é bem menor que 0.05, o que indica que há autocorrelação positiva, ou seja, a hipótse nula de que não há autocorrelação positiva é rejeitada.

+ Deaths Air Pollution

```{r}
# Teste de Durbin-Watson
dwtest(dap_rls, ~ deaths_air_pollution, data = owid)
```

O p-valor é bem menor que 0.05, o que indica que há autocorrelação positiva, ou seja, a hipótse nula de que não há autocorrelação positiva é rejeitada.

+ Expected Schooling

```{r}
# Teste de Durbin-Watson
dwtest(es_rls, ~ expected_schooling, data = owid)
```

O p-valor é bem menor que 0.05, o que indica que há autocorrelação positiva, ou seja, a hipótse nula de que não há autocorrelação positiva é rejeitada.

+ Life Expectancy

```{r}
# Teste de Durbin-Watson
dwtest(le_rls, ~ life_expectancy, data = owid)
```

O p-valor é bem menor que 0.05, o que indica que há autocorrelação positiva, ou seja, a hipótse nula de que não há autocorrelação positiva é rejeitada.

##### Normalidade

Para a normalidade iremos utilizar o teste de Shapiro-Wilk. E gráficamente iremos utilizar o gráfico de probabilidade normal.

+ Birth Rate

```{r}
# Teste de Shapiro-Wilk
shapiro.test(br_rls$res)
```

O p-valor é bem menor que 0.05, o que indica que não há normalidade, ou seja, a hipótse nula de que há normalidade é rejeitada. Assim, concluimos que os erros não são normalmente distribuídos.

Para complementar, analisaremo o gráfico de probabilidade normal.

```{r}
# Gráfico de probabilidade normal
qqnorm(br_rls$res)
qqline(br_rls$res)
```

E também o histograma dos resíduos.

```{r}
# Histograma dos resíduos
ggplot(br_rls_data, aes(x = resid)) +
  geom_histogram(bins = 20) +
  ggtitle("dados originais: modelo hcl ~ br") +
  labs(y = "frequência", x = "resíduos")
```

+ Deaths Air Pollution

```{r}
# Teste de Shapiro-Wilk
shapiro.test(dap_rls$res)
```

O p-valor é menor que 0.05, o que indica que não há normalidade, ou seja, a hipótse nula de que há normalidade é rejeitada. Assim, concluimos que os erros não são normalmente distribuídos.

Para complementar, analisaremo o gráfico de probabilidade normal.

```{r}
# Gráfico de probabilidade normal
qqnorm(dap_rls$res)
qqline(dap_rls$res)
```

E também o histograma dos resíduos.

```{r}
# Histograma dos resíduos
ggplot(dap_rls_data, aes(x = resid)) +
  geom_histogram(bins = 20) +
  ggtitle("dados originais: modelo hcl ~ dap") +
  labs(y = "frequência", x = "resíduos")
```

+ Expected Schooling

```{r}
# Teste de Shapiro-Wilk
shapiro.test(es_rls$res)
```

O p-valor é menor que 0.05, o que indica que não há normalidade, ou seja, a hipótse nula de que há normalidade é rejeitada. Assim, concluimos que os erros não são normalmente distribuídos.

Para complementar, analisaremo o gráfico de probabilidade normal.

```{r}
# Gráfico de probabilidade normal
qqnorm(es_rls$res)
qqline(es_rls$res)
```

E também o histograma dos resíduos.

```{r}
# Histograma dos resíduos
ggplot(es_rls_data, aes(x = resid)) +
  geom_histogram(bins = 20) +
  ggtitle("dados originais: modelo hcl ~ es") +
  labs(y = "frequência", x = "resíduos")
```

+ Life Expectancy

```{r}
# Teste de Shapiro-Wilk
shapiro.test(le_rls$res)
```

O p-valor é bem menor que 0.05, o que indica que não há normalidade, ou seja, a hipótse nula de que há normalidade é rejeitada. Assim, concluimos que os erros não são normalmente distribuídos.

Para complementar, analisaremo o gráfico de probabilidade normal.

```{r}
# Gráfico de probabilidade normal
qqnorm(le_rls$res)
qqline(le_rls$res)
```

E também o histograma dos resíduos.

```{r}
# Histograma dos resíduos
ggplot(le_rls_data, aes(x = resid)) +
  geom_histogram(bins = 20) +
  ggtitle("dados originais: modelo hcl ~ le") +
  labs(y = "frequência", x = "resíduos")
```

2. Ajuste um modelo de regressão linear simples para a variável `happiness_cantril_ladder` como função de `deaths_air_pollution` após excluir as observações 973 (X = 237 e Y = 6.00), 974 (X = 234 e Y = 5.99) e 975 (X = 225 e Y = 5.97). Obtenha intervalos de previsão de 95% de confiança para novas observações que apresentam valores da variável explicativa iguais a 237, 234 e 225. As observações eliminadas encontram-se nos limites dos intervalos de previsão obtidos? Discuta o significado dos resultados obtidos.

inicialmente precisamos excluir as observações 973, 974 e 975.

```{r}
# Excluindo as observações
hcl_dap <- lm(happiness_cantril_ladder ~ deaths_air_pollution, data = slice(owid,-c(973, 974, 975)))

# Intervalos de previsão
predict(hcl_dap, newdata = data.frame(deaths_air_pollution = c(237, 234, 225)), interval = "prediction", level = 0.95)

```	

Podemos perceber que em um intervalo de confiança de 95% as observações as observações 973, 974 e 975 não estão nos limites dos intervalos de previsão. O que é um indício de que essas observações são outliers.

3. Para os modelos considerando cada nível da variável `continent` no item (2) da seção anterior, realize o diagnóstico através da análise dos resíduos. Todos aparentam ter mesma variância dos erros? É necessário realizar alguma transformação de variáveis? Tente solucionar os possíveis problemas encontrados com o modelo. Que conclusões é possível obter a partir da análise?


------------------------------------------------------------------------